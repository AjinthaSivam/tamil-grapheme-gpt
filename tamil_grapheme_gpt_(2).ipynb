{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AjinthaSivam/tamil-grapheme-gpt/blob/main/tamil_grapheme_gpt_(2).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CkAivJU-gn0q"
      },
      "source": [
        "# Tamil Grapheme-Level Decoder-Only Transformer\n",
        "\n",
        "This notebook implements a grapheme-level (instead of character-level) transformer for Tamil text generation.\n",
        "Grapheme tokenization treats Tamil consonant-vowel combinations as single units, which is more linguistically appropriate."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvtGAcjagn0v",
        "outputId": "121dd4d2-7894-49a1-b670-624810e51321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu128)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting grapheme\n",
            "  Downloading grapheme-0.6.0.tar.gz (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (1.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.5.4)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (0.21.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2026.1.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.3)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub>=0.24.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface-hub>=0.24.0->datasets) (8.3.1)\n",
            "Building wheels for collected packages: grapheme\n",
            "  Building wheel for grapheme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grapheme: filename=grapheme-0.6.0-py3-none-any.whl size=210082 sha256=d331fcc8e9654d1a3ae970e463d8551745cf787fa7d298c9596e9a517b2ab9b2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/aa/3b/d94434910f5e19ac7f8aa6523d74a46fe06bfcbc7e4b26caf6\n",
            "Successfully built grapheme\n",
            "Installing collected packages: grapheme\n",
            "Successfully installed grapheme-0.6.0\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "!pip install torch datasets grapheme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bbWN2mOWgn0x"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import grapheme\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1UG8an_gn0y"
      },
      "source": [
        "## Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzXCU5Cxgn0y",
        "outputId": "42051fc6-3eff-4a90-982c-dd9df6341d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters\n",
        "batch_size = 64\n",
        "block_size = 256\n",
        "max_iters = 30000\n",
        "eval_interval = 500\n",
        "learning_rate = 2e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 96\n",
        "n_head = 3\n",
        "n_layer = 4\n",
        "dropout = 0.2\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "torch.manual_seed(1337)\n",
        "\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "08QPTRn7gn0z"
      },
      "source": [
        "## Mount Google Drive and Extract Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9HuWe2XQgn00",
        "outputId": "d8ec4784-1bae-4358-9b8b-9560e45c5753"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfLKDF12gn01",
        "outputId": "76db5d09-fb0e-4ab9-df62-85a936dbd84b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found zip file: /content/drive/MyDrive/tamil_data/lk_news_2/v2_split_2024.zip\n",
            "Extracting /content/drive/MyDrive/tamil_data/lk_news_2/v2_split_2024.zip...\n",
            "Found 8895 files in archive\n",
            "Extraction complete!\n",
            "\n",
            "Using data directory: /content/tamil_data_extracted/2024/2024\n",
            "Number of JSON files found: 8894\n",
            "Sample files: ['2024-03-04-tamilmirrorlk-6c979f2c_split.json', '2024-02-02-tamilmirrorlk-1daea565_split.json', '2024-01-20-tamilmirrorlk-c8ae20ee_split.json', '2024-10-07-tamilmirrorlk-e51800c3_split.json', '2024-05-27-tamilmirrorlk-9fb2cbfa_split.json']\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "# === CONFIGURATION: Choose your setup ===\n",
        "# Option 1: If your data is in a zip file\n",
        "ZIP_PATH = '/content/drive/MyDrive/tamil_data/lk_news_2/v2_split_2024.zip'\n",
        "\n",
        "# Option 2: If your data is already in a folder (not zipped)\n",
        "# Uncomment the line below and comment out the extraction code if not using zip\n",
        "# DATA_DIR = '/content/drive/MyDrive/tamil_data/lk_news/tamilmirror/2024'\n",
        "\n",
        "# Directory to extract to (in Colab's local storage for faster access)\n",
        "EXTRACT_DIR = '/content/tamil_data_extracted/2024'\n",
        "\n",
        "# Check if zip file exists and extract\n",
        "if os.path.exists(ZIP_PATH):\n",
        "    print(f\"Found zip file: {ZIP_PATH}\")\n",
        "\n",
        "    # Create extraction directory\n",
        "    os.makedirs(EXTRACT_DIR, exist_ok=True)\n",
        "\n",
        "    # Check if already extracted\n",
        "    if len(os.listdir(EXTRACT_DIR)) > 0:\n",
        "        print(f\"Data already extracted to {EXTRACT_DIR}\")\n",
        "    else:\n",
        "        print(f\"Extracting {ZIP_PATH}...\")\n",
        "        with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "            # Show progress\n",
        "            members = zip_ref.namelist()\n",
        "            print(f\"Found {len(members)} files in archive\")\n",
        "            zip_ref.extractall(EXTRACT_DIR)\n",
        "        print(f\"Extraction complete!\")\n",
        "\n",
        "    DATA_DIR = f'{EXTRACT_DIR}/2024'\n",
        "\n",
        "else:\n",
        "    print(f\"Zip file not found at {ZIP_PATH}\")\n",
        "    print(\"Please update ZIP_PATH or DATA_DIR variable with the correct path\")\n",
        "    # If zip doesn't exist, try using direct folder path\n",
        "    DATA_DIR = '/content/drive/MyDrive/tamil_data/lk_news/tamilmirror/2024'\n",
        "\n",
        "print(f\"\\nUsing data directory: {DATA_DIR}\")\n",
        "\n",
        "# Verify the directory exists and has files\n",
        "if os.path.exists(DATA_DIR):\n",
        "    files = [f for f in os.listdir(DATA_DIR) if f.endswith('.json')]\n",
        "    print(f\"Number of JSON files found: {len(files)}\")\n",
        "    if len(files) > 0:\n",
        "        print(f\"Sample files: {files[:5]}\")\n",
        "    else:\n",
        "        print(\"WARNING: No JSON files found in directory!\")\n",
        "else:\n",
        "    print(f\"ERROR: Directory {DATA_DIR} does not exist!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvwdYABDgn01"
      },
      "source": [
        "## Data Loading and Grapheme Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyZwuDC3gn02",
        "outputId": "7301301e-8f59-40ad-a5ed-828aac291dee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 8894 JSON files\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading JSON files: 100%|██████████| 8894/8894 [00:00<00:00, 20449.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 60462 text samples\n",
            "Total characters: 8011303\n",
            "Sample text: காதலனுக்காக சிறுமி செய்த செயல்; இறுதியில் இருவரும் கைது\n",
            "வாதுவை - பொஹத்தரமுல்ல கடற்கரை பகுதியில் போதைப்பொருளுடன் 17 வயது சிறுமியும் அவரது 30 வயதான காதலரும் கைது செய்யப்பட்டுள்ளனர்.\n",
            "சந்தேக நபரான சிறுமி \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "def load_json_texts(data_dir):\n",
        "    \"\"\"\n",
        "    Load all JSON files from a specified directory and extract the 'text' field.\n",
        "    Handles the actual dataset structure where JSON contains:\n",
        "    {\n",
        "        \"sentences\": [\n",
        "            {\"id\": 1, \"text\": \"...\"},\n",
        "            {\"id\": 2, \"text\": \"...\"}\n",
        "        ]\n",
        "    }\n",
        "    \"\"\"\n",
        "    all_texts = []\n",
        "    json_files = list(Path(data_dir).glob('*.json'))\n",
        "\n",
        "    print(f\"Found {len(json_files)} JSON files\")\n",
        "\n",
        "    for json_file in tqdm(json_files, desc=\"Loading JSON files\"):\n",
        "        try:\n",
        "            with open(json_file, 'r', encoding='utf-8') as f:\n",
        "                data = json.load(f)\n",
        "\n",
        "                # Extract text from sentences\n",
        "                if 'sentences' in data and isinstance(data['sentences'], list):\n",
        "                    for sentence in data['sentences']:\n",
        "                        if isinstance(sentence, dict) and 'text' in sentence:\n",
        "                            text = sentence['text'].strip()\n",
        "                            if text:\n",
        "                                all_texts.append(text)\n",
        "        except Exception as e:\n",
        "            print(f\"Error loading {json_file}: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"Loaded {len(all_texts)} text samples\")\n",
        "    return all_texts\n",
        "\n",
        "# Load the data\n",
        "texts = load_json_texts(DATA_DIR)\n",
        "full_text = '\\n'.join(texts)\n",
        "print(f\"Total characters: {len(full_text)}\")\n",
        "print(f\"Sample text: {full_text[:200]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H9HnpsLpgn02",
        "outputId": "2faae428-2944-4e64-bfb7-c96b5d2b9589"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting text to graphemes...\n",
            "Total graphemes: 5175615\n",
            "Vocabulary size (unique graphemes): 454\n",
            "Sample graphemes: ['ஆ', 'ஆா்', 'இ', 'இ்', 'ஈ', 'உ', 'ஊ', 'எ', 'எ்', 'ஏ', 'ஐ', 'ஒ', 'ஓ', 'ஔ', 'ஔி', 'க', 'கா', 'காெ', 'கா்', 'கி']\n"
          ]
        }
      ],
      "source": [
        "# Grapheme tokenization\n",
        "def text_to_graphemes(text):\n",
        "    \"\"\"Convert text to a list of graphemes\"\"\"\n",
        "    return list(grapheme.graphemes(text))\n",
        "\n",
        "def graphemes_to_text(graphemes):\n",
        "    \"\"\"Convert list of graphemes back to text\"\"\"\n",
        "    return ''.join(graphemes)\n",
        "\n",
        "# Convert entire text to graphemes\n",
        "print(\"Converting text to graphemes...\")\n",
        "all_graphemes = text_to_graphemes(full_text)\n",
        "print(f\"Total graphemes: {len(all_graphemes)}\")\n",
        "\n",
        "# Build vocabulary from graphemes\n",
        "unique_graphemes = sorted(list(set(all_graphemes)))\n",
        "vocab_size = len(unique_graphemes)\n",
        "print(f\"Vocabulary size (unique graphemes): {vocab_size}\")\n",
        "print(f\"Sample graphemes: {unique_graphemes[100:120]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LDvJzEvfgn03",
        "outputId": "84170ed1-312c-423b-cb3c-1259612f3356"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original: காதலனுக்காக சிறுமி செய்த செயல்; இறுதியில் இருவரும் கைது\n",
            "Encoded (first 20): [116, 201, 349, 249, 133, 116, 115, 1, 140, 337, 282, 1, 144, 315, 201, 1, 144, 297, 365, 28]\n",
            "Decoded: காதலனுக்காக சிறுமி செய்த செயல்; இறுதியில் இருவரும் கைது\n",
            "Match: True\n"
          ]
        }
      ],
      "source": [
        "# Create grapheme-to-index and index-to-grapheme mappings\n",
        "gtoi = {g: i for i, g in enumerate(unique_graphemes)}\n",
        "itog = {i: g for i, g in enumerate(unique_graphemes)}\n",
        "\n",
        "# Encode and decode functions\n",
        "def encode(text):\n",
        "    \"\"\"Convert text to list of grapheme indices\"\"\"\n",
        "    graphemes = text_to_graphemes(text)\n",
        "    return [gtoi[g] for g in graphemes]\n",
        "\n",
        "def decode(indices):\n",
        "    \"\"\"Convert list of grapheme indices back to text\"\"\"\n",
        "    graphemes = [itog[i] for i in indices]\n",
        "    return graphemes_to_text(graphemes)\n",
        "\n",
        "# Test encoding and decoding\n",
        "test_text = texts[0][:100] if texts else \"வணக்கம்\"\n",
        "encoded = encode(test_text)\n",
        "decoded = decode(encoded)\n",
        "print(f\"Original: {test_text}\")\n",
        "print(f\"Encoded (first 20): {encoded[:20]}\")\n",
        "print(f\"Decoded: {decoded}\")\n",
        "print(f\"Match: {test_text == decoded}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbFytrM2gn04",
        "outputId": "bc865ad2-8c25-4ed6-9a3c-1db6526ee225"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding entire dataset...\n",
            "Data tensor shape: torch.Size([5175615])\n",
            "Train size: 4658053, Val size: 517562\n"
          ]
        }
      ],
      "source": [
        "# Encode entire dataset\n",
        "print(\"Encoding entire dataset...\")\n",
        "data = torch.tensor(encode(full_text), dtype=torch.long)\n",
        "print(f\"Data tensor shape: {data.shape}\")\n",
        "\n",
        "# Train-validation split\n",
        "n = int(0.9 * len(data))\n",
        "train_data = data[:n]\n",
        "val_data = data[n:]\n",
        "print(f\"Train size: {len(train_data)}, Val size: {len(val_data)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JN3MgY1Egn04"
      },
      "source": [
        "## Data Batch Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "q28vdRt7gn05"
      },
      "outputs": [],
      "source": [
        "def get_batch(split):\n",
        "    \"\"\"Generate a small batch of data of inputs x and targets y\"\"\"\n",
        "    data_split = train_data if split == 'train' else val_data\n",
        "    ix = torch.randint(len(data_split) - block_size, (batch_size,))\n",
        "    x = torch.stack([data_split[i:i+block_size] for i in ix])\n",
        "    y = torch.stack([data_split[i+1:i+block_size+1] for i in ix])\n",
        "    x, y = x.to(device), y.to(device)\n",
        "    return x, y\n",
        "\n",
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "    \"\"\"Estimate loss on train and val sets\"\"\"\n",
        "    out = {}\n",
        "    model.eval()\n",
        "    for split in ['train', 'val']:\n",
        "        losses = torch.zeros(eval_iters)\n",
        "        for k in range(eval_iters):\n",
        "            X, Y = get_batch(split)\n",
        "            logits, loss = model(X, Y)\n",
        "            losses[k] = loss.item()\n",
        "        out[split] = losses.mean()\n",
        "    model.train()\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lEeQFO1xgn06"
      },
      "source": [
        "## Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "qmamaL8cgn06",
        "outputId": "38e09e88-514b-4e2a-ee25-c9bc297ef293"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 0.56M\n",
            "GraphemeGPT(\n",
            "  (token_embedding_table): Embedding(454, 96)\n",
            "  (position_embedding_table): Embedding(256, 96)\n",
            "  (blocks): Sequential(\n",
            "    (0): Block(\n",
            "      (sa): MultiHeadAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0-2): 3 x Head(\n",
            "            (key): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (query): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (value): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ffwd): FeedFoward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=384, out_features=96, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (1): Block(\n",
            "      (sa): MultiHeadAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0-2): 3 x Head(\n",
            "            (key): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (query): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (value): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ffwd): FeedFoward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=384, out_features=96, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (2): Block(\n",
            "      (sa): MultiHeadAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0-2): 3 x Head(\n",
            "            (key): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (query): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (value): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ffwd): FeedFoward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=384, out_features=96, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (3): Block(\n",
            "      (sa): MultiHeadAttention(\n",
            "        (heads): ModuleList(\n",
            "          (0-2): 3 x Head(\n",
            "            (key): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (query): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (value): Linear(in_features=96, out_features=32, bias=False)\n",
            "            (dropout): Dropout(p=0.2, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (proj): Linear(in_features=96, out_features=96, bias=True)\n",
            "        (dropout): Dropout(p=0.2, inplace=False)\n",
            "      )\n",
            "      (ffwd): FeedFoward(\n",
            "        (net): Sequential(\n",
            "          (0): Linear(in_features=96, out_features=384, bias=True)\n",
            "          (1): ReLU()\n",
            "          (2): Linear(in_features=384, out_features=96, bias=True)\n",
            "          (3): Dropout(p=0.2, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (ln1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "      (ln2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (ln_f): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
            "  (lm_head): Linear(in_features=96, out_features=454, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "class Head(nn.Module):\n",
        "    \"\"\"One head of self-attention\"\"\"\n",
        "\n",
        "    def __init__(self, head_size):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.shape\n",
        "        k = self.key(x)   # (B, T, head_size)\n",
        "        q = self.query(x) # (B, T, head_size)\n",
        "\n",
        "        # Compute attention scores\n",
        "        wei = q @ k.transpose(-2, -1) * (C ** -0.5)  # (B, T, T)\n",
        "        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf'))\n",
        "        wei = F.softmax(wei, dim=-1)\n",
        "        wei = self.dropout(wei)\n",
        "\n",
        "        # Weighted aggregation of values\n",
        "        v = self.value(x)  # (B, T, head_size)\n",
        "        out = wei @ v      # (B, T, head_size)\n",
        "        return out\n",
        "\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\"Multiple heads of self-attention in parallel\"\"\"\n",
        "\n",
        "    def __init__(self, num_heads, head_size):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "        out = self.dropout(self.proj(out))\n",
        "        return out\n",
        "\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\"A simple linear layer followed by a non-linearity\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "    \"\"\"Transformer block: communication followed by computation\"\"\"\n",
        "\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "        self.sa = MultiHeadAttention(n_head, head_size)\n",
        "        self.ffwd = FeedFoward(n_embd)\n",
        "        self.ln1 = nn.LayerNorm(n_embd)\n",
        "        self.ln2 = nn.LayerNorm(n_embd)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.sa(self.ln1(x))\n",
        "        x = x + self.ffwd(self.ln2(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class GraphemeGPT(nn.Module):\n",
        "    \"\"\"Grapheme-level language model\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n",
        "        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n",
        "        self.ln_f = nn.LayerNorm(n_embd)\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        B, T = idx.shape\n",
        "\n",
        "        # idx and targets are both (B,T) tensor of integers\n",
        "        tok_emb = self.token_embedding_table(idx)  # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table(torch.arange(T, device=device))  # (T,C)\n",
        "        x = tok_emb + pos_emb  # (B,T,C)\n",
        "        x = self.blocks(x)     # (B,T,C)\n",
        "        x = self.ln_f(x)       # (B,T,C)\n",
        "        logits = self.lm_head(x)  # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "            loss = None\n",
        "        else:\n",
        "            B, T, C = logits.shape\n",
        "            logits = logits.view(B*T, C)\n",
        "            targets = targets.view(B*T)\n",
        "            loss = F.cross_entropy(logits, targets)\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, max_new_tokens):\n",
        "        # idx is (B, T) array of indices in the current context\n",
        "        for _ in range(max_new_tokens):\n",
        "            # Crop idx to the last block_size tokens\n",
        "            idx_cond = idx[:, -block_size:]\n",
        "            # Get the predictions\n",
        "            logits, loss = self(idx_cond)\n",
        "            # Focus only on the last time step\n",
        "            logits = logits[:, -1, :]  # becomes (B, C)\n",
        "            # Apply softmax to get probabilities\n",
        "            probs = F.softmax(logits, dim=-1)  # (B, C)\n",
        "            # Sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)  # (B, 1)\n",
        "            # Append sampled index to the running sequence\n",
        "            idx = torch.cat((idx, idx_next), dim=1)  # (B, T+1)\n",
        "        return idx\n",
        "\n",
        "# Create model\n",
        "model = GraphemeGPT()\n",
        "model = model.to(device)\n",
        "\n",
        "# Print the number of parameters in the model\n",
        "print(f\"Model parameters: {sum(p.numel() for p in model.parameters()) / 1e6:.2f}M\")\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzUuID7Ngn08"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MsMjdnhygn08",
        "outputId": "ffd54ab4-4754-4ad6-8492-84dac97f6829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting training...\n",
            "step 0: train loss 6.3143, val loss 6.3141\n",
            "  → Saved best model (val loss: 6.3141)\n",
            "step 500: train loss 3.0806, val loss 3.0701\n",
            "  → Saved best model (val loss: 3.0701)\n",
            "step 1000: train loss 2.8935, val loss 2.8897\n",
            "  → Saved best model (val loss: 2.8897)\n",
            "step 1500: train loss 2.8212, val loss 2.8159\n",
            "  → Saved best model (val loss: 2.8159)\n",
            "step 2000: train loss 2.7660, val loss 2.7636\n",
            "  → Saved best model (val loss: 2.7636)\n",
            "step 2500: train loss 2.6812, val loss 2.6815\n",
            "  → Saved best model (val loss: 2.6815)\n",
            "step 3000: train loss 2.5815, val loss 2.5827\n",
            "  → Saved best model (val loss: 2.5827)\n",
            "step 3500: train loss 2.4887, val loss 2.4917\n",
            "  → Saved best model (val loss: 2.4917)\n",
            "step 4000: train loss 2.4080, val loss 2.4157\n",
            "  → Saved best model (val loss: 2.4157)\n",
            "step 4500: train loss 2.3334, val loss 2.3358\n",
            "  → Saved best model (val loss: 2.3358)\n",
            "step 5000: train loss 2.2722, val loss 2.2773\n",
            "  → Saved best model (val loss: 2.2773)\n",
            "step 5500: train loss 2.2120, val loss 2.2215\n",
            "  → Saved best model (val loss: 2.2215)\n",
            "step 6000: train loss 2.1611, val loss 2.1707\n",
            "  → Saved best model (val loss: 2.1707)\n",
            "step 6500: train loss 2.1146, val loss 2.1256\n",
            "  → Saved best model (val loss: 2.1256)\n",
            "step 7000: train loss 2.0812, val loss 2.0841\n",
            "  → Saved best model (val loss: 2.0841)\n",
            "step 7500: train loss 2.0420, val loss 2.0545\n",
            "  → Saved best model (val loss: 2.0545)\n",
            "step 8000: train loss 2.0079, val loss 2.0190\n",
            "  → Saved best model (val loss: 2.0190)\n",
            "step 8500: train loss 1.9826, val loss 1.9914\n",
            "  → Saved best model (val loss: 1.9914)\n",
            "step 9000: train loss 1.9604, val loss 1.9728\n",
            "  → Saved best model (val loss: 1.9728)\n",
            "step 9500: train loss 1.9396, val loss 1.9455\n",
            "  → Saved best model (val loss: 1.9455)\n",
            "step 10000: train loss 1.9168, val loss 1.9254\n",
            "  → Saved best model (val loss: 1.9254)\n",
            "step 10500: train loss 1.8997, val loss 1.9125\n",
            "  → Saved best model (val loss: 1.9125)\n",
            "step 11000: train loss 1.8845, val loss 1.8949\n",
            "  → Saved best model (val loss: 1.8949)\n",
            "step 11500: train loss 1.8639, val loss 1.8770\n",
            "  → Saved best model (val loss: 1.8770)\n",
            "step 12000: train loss 1.8487, val loss 1.8632\n",
            "  → Saved best model (val loss: 1.8632)\n",
            "step 12500: train loss 1.8395, val loss 1.8516\n",
            "  → Saved best model (val loss: 1.8516)\n",
            "step 13000: train loss 1.8254, val loss 1.8422\n",
            "  → Saved best model (val loss: 1.8422)\n",
            "step 13500: train loss 1.8136, val loss 1.8275\n",
            "  → Saved best model (val loss: 1.8275)\n",
            "step 14000: train loss 1.8021, val loss 1.8197\n",
            "  → Saved best model (val loss: 1.8197)\n",
            "step 14500: train loss 1.7920, val loss 1.8065\n",
            "  → Saved best model (val loss: 1.8065)\n",
            "step 15000: train loss 1.7830, val loss 1.8004\n",
            "  → Saved best model (val loss: 1.8004)\n",
            "step 15500: train loss 1.7800, val loss 1.7892\n",
            "  → Saved best model (val loss: 1.7892)\n",
            "step 16000: train loss 1.7717, val loss 1.7807\n",
            "  → Saved best model (val loss: 1.7807)\n",
            "step 16500: train loss 1.7562, val loss 1.7758\n",
            "  → Saved best model (val loss: 1.7758)\n",
            "step 17000: train loss 1.7467, val loss 1.7683\n",
            "  → Saved best model (val loss: 1.7683)\n",
            "step 17500: train loss 1.7359, val loss 1.7603\n",
            "  → Saved best model (val loss: 1.7603)\n",
            "step 18000: train loss 1.7319, val loss 1.7536\n",
            "  → Saved best model (val loss: 1.7536)\n",
            "step 18500: train loss 1.7244, val loss 1.7453\n",
            "  → Saved best model (val loss: 1.7453)\n",
            "step 19000: train loss 1.7176, val loss 1.7376\n",
            "  → Saved best model (val loss: 1.7376)\n",
            "step 19500: train loss 1.7102, val loss 1.7300\n",
            "  → Saved best model (val loss: 1.7300)\n",
            "step 20000: train loss 1.7021, val loss 1.7293\n",
            "  → Saved best model (val loss: 1.7293)\n",
            "step 20500: train loss 1.6980, val loss 1.7202\n",
            "  → Saved best model (val loss: 1.7202)\n",
            "step 21000: train loss 1.6944, val loss 1.7104\n",
            "  → Saved best model (val loss: 1.7104)\n",
            "step 21500: train loss 1.6857, val loss 1.7067\n",
            "  → Saved best model (val loss: 1.7067)\n",
            "step 22000: train loss 1.6797, val loss 1.7016\n",
            "  → Saved best model (val loss: 1.7016)\n",
            "step 22500: train loss 1.6762, val loss 1.6966\n",
            "  → Saved best model (val loss: 1.6966)\n",
            "step 23000: train loss 1.6735, val loss 1.6909\n",
            "  → Saved best model (val loss: 1.6909)\n",
            "step 23500: train loss 1.6665, val loss 1.6877\n",
            "  → Saved best model (val loss: 1.6877)\n",
            "step 24000: train loss 1.6622, val loss 1.6811\n",
            "  → Saved best model (val loss: 1.6811)\n",
            "step 24500: train loss 1.6564, val loss 1.6800\n",
            "  → Saved best model (val loss: 1.6800)\n",
            "step 25000: train loss 1.6559, val loss 1.6742\n",
            "  → Saved best model (val loss: 1.6742)\n",
            "step 25500: train loss 1.6436, val loss 1.6746\n",
            "step 26000: train loss 1.6431, val loss 1.6656\n",
            "  → Saved best model (val loss: 1.6656)\n",
            "step 26500: train loss 1.6381, val loss 1.6663\n",
            "step 27000: train loss 1.6355, val loss 1.6605\n",
            "  → Saved best model (val loss: 1.6605)\n",
            "step 27500: train loss 1.6315, val loss 1.6542\n",
            "  → Saved best model (val loss: 1.6542)\n",
            "step 28000: train loss 1.6306, val loss 1.6557\n",
            "step 28500: train loss 1.6263, val loss 1.6540\n",
            "  → Saved best model (val loss: 1.6540)\n",
            "step 29000: train loss 1.6233, val loss 1.6458\n",
            "  → Saved best model (val loss: 1.6458)\n",
            "step 29500: train loss 1.6195, val loss 1.6427\n",
            "  → Saved best model (val loss: 1.6427)\n",
            "step 29999: train loss 1.6167, val loss 1.6372\n",
            "  → Saved best model (val loss: 1.6372)\n",
            "\n",
            "Training complete! Best validation loss: 1.6372\n"
          ]
        }
      ],
      "source": [
        "# Create optimizer\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Training loop\n",
        "best_val_loss = float('inf')\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for iter in range(max_iters):\n",
        "\n",
        "    # Every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "        losses = estimate_loss()\n",
        "        train_losses.append(losses['train'])\n",
        "        val_losses.append(losses['val'])\n",
        "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "        # Save best model\n",
        "        if losses['val'] < best_val_loss:\n",
        "            best_val_loss = losses['val']\n",
        "            torch.save({\n",
        "                'iter': iter,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'train_loss': losses['train'],\n",
        "                'val_loss': losses['val'],\n",
        "                'vocab_size': vocab_size,\n",
        "                'gtoi': gtoi,\n",
        "                'itog': itog,\n",
        "                'unique_graphemes': unique_graphemes\n",
        "            }, 'best_grapheme_model.pt')\n",
        "            print(f\"  → Saved best model (val loss: {best_val_loss:.4f})\")\n",
        "\n",
        "    # Sample a batch of data\n",
        "    xb, yb = get_batch('train')\n",
        "\n",
        "    # Evaluate the loss\n",
        "    logits, loss = model(xb, yb)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "print(f\"\\nTraining complete! Best validation loss: {best_val_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SQzyffKFgn09"
      },
      "source": [
        "## Text Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J3VbKFG9gn09",
        "outputId": "982e3d91-eba6-4f0a-ad9f-45502ae90672"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded model from iteration 29999\n",
            "Val loss: 1.6372\n"
          ]
        }
      ],
      "source": [
        "# Load best model\n",
        "checkpoint = torch.load('best_grapheme_model.pt', map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])\n",
        "model.eval()\n",
        "\n",
        "print(f\"Loaded model from iteration {checkpoint['iter']}\")\n",
        "print(f\"Val loss: {checkpoint['val_loss']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHCVo-wTgn09",
        "outputId": "d6e1444e-20c6-45c9-c5b5-3bb2840f220c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated text (no prompt):\n",
            "================================================================================\n",
            "\n",
            "இனந்த அண்மையில் முன்னெடுக்கப்பட்டதாகவும் செயற்படுவது தெரிவித்துள்ளது.\n",
            "30 கிராமவின் முதலில் விஞ்ஞான ரயில்வே கட்டல் மார்க்க விலகி அமைச்சின் மாதம் நோயாளிகள் தொடர்பான சத்திரம் இல்லை\"\n",
            "பாதிக்கப்பட்ட முறைப்பாடுகள் உறுதிப்படுத்தப்படும் முதலீடு செய்யப்பட்டிருந்தனர்.\n",
            "மக்கள் சர்வதேசன கண்டி அனைவரும் தரத்தை வழிதற்கு முன்பம் ஆசனங்கள், SJBDPA தேசிய ஔட (SDE) பணிகளையும் ஏற்கனவேண்டியுள்ளது.\n",
            "இப்போது இதனால் அடைவதாகவும் அதேபோன் சமுனதா வீட்டில் போன்ற தாக்களை பெற்றுக்கொண்டிரு\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Generate text\n",
        "def generate_text(prompt=\"\", max_new_tokens=500):\n",
        "    \"\"\"Generate text from a prompt (or from scratch if no prompt)\"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    if prompt:\n",
        "        context = torch.tensor([encode(prompt)], dtype=torch.long, device=device)\n",
        "    else:\n",
        "        # Start from a random grapheme\n",
        "        context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "\n",
        "    generated = model.generate(context, max_new_tokens=max_new_tokens)\n",
        "    return decode(generated[0].tolist())\n",
        "\n",
        "# Generate some samples\n",
        "print(\"Generated text (no prompt):\")\n",
        "print(\"=\" * 80)\n",
        "print(generate_text(max_new_tokens=300))\n",
        "print(\"\\n\" + \"=\" * 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TQ-ioGxgn0-",
        "outputId": "ab34aa9e-cb2b-42de-8e8d-89f8415e2391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Prompt: 'அரசாங்கம்'\n",
            "================================================================================\n",
            "அரசாங்கம் விட்டுச் செவ்வாய்க்கிழமை (06) இராஜினாமா\n",
            "பிரதமர் பிராந்தித்தில் மூம் வகையில் திகதிக்கப்பட்டுள்ளது.\n",
            "ரஷ்யாவுகளில் பாதிக்கப்பட்ட புத்தளம் - தலைமையில் ஒரு யிருப்பதாக வெளியிடப்பட்ட மழையின் மேலதிக பலி\n",
            "மேல், பெய்யக்கூடும் என தெரிவித்தப்பட்ட தண்டார வடக்கு வளிமண்டலவியல் திணைக்களம் வழங்கவும், அமையுடன் கூடிய மழையோ இ\n",
            "================================================================================\n",
            "\n",
            "Prompt: 'இலங்கை'\n",
            "================================================================================\n",
            "இலங்கைப்பாணம் செய்யப்பட்டது, 228 ரூபா/L 212814 ரூபாய் 117 போ் மீற்றர் முறையில் 30% கான்பற்று செற்பாட்டமாகவும், பிற்பகல் 150 ரூபாவிற்கு முன்னர், அதை ஞாய்வு பாரதூட்டில் இதனை சிலர்கள் கடைப்படுத்தப்பட்டுள்ளமை குறிப்பிடத்தக்கது.\n",
            "ஆனால், எனினுந்த பாலியல் விளக்கமறியலில் வைக்கப்பட்டனர்.\n",
            "குறுகிய குற்றம்பதிவாக நபர்க\n",
            "================================================================================\n",
            "\n",
            "Prompt: 'சனாதிபதி'\n",
            "================================================================================\n",
            "சனாதிபதி கிடைத்த ஆண்டு அதிசரமாக, தேர்தலில் இஸ்ரேல் ஜயவீர தனது அமைச்சர் தெரிவித்தார்.\n",
            "ஜனாதிபதி ரணில் விக்கிரமசிங்கவை, என்ற நிலையே நவம்புக்கு கொடுப்பதற்கு எடுக்கும் என தெரிவித்தனர்.\n",
            "ஹோவ தேர்தலில் வெளியிட்டனர்.\n",
            "பாரஸ் ரத்நாயக்க இலஞ்சம் (14) நள்ளிரவு செலவு திட்டத்தைத் தவறானது முறைப்பாடு அல்லது மக்கள் மற்றும் பெய\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Try with a prompt\n",
        "prompts = [\n",
        "    \"அரசாங்கம்\",\n",
        "    \"இலங்கை\",\n",
        "    \"சனாதிபதி\",\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    print(f\"\\nPrompt: '{prompt}'\")\n",
        "    print(\"=\" * 80)\n",
        "    generated = generate_text(prompt=prompt, max_new_tokens=200)\n",
        "    print(generated)\n",
        "    print(\"=\" * 80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltqStPcign0-"
      },
      "source": [
        "## Model Evaluation Metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "VQOuqJKRgn0-"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2nMHY9tgn0_",
        "outputId": "bb75aa9b-ce0e-4c09-f362-92bf0cf1b49e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================================================================\n",
            "COMPREHENSIVE MODEL EVALUATION\n",
            "================================================================================\n",
            "\n",
            "1. LOSS AND PERPLEXITY\n",
            "----------------------------------------\n",
            "Training Set:\n",
            "  Loss:       1.6119\n",
            "  Perplexity: 5.0126\n",
            "\n",
            "Validation Set:\n",
            "  Loss:       1.6400\n",
            "  Perplexity: 5.1550\n",
            "\n",
            "\n",
            "2. PREDICTION ACCURACY\n",
            "----------------------------------------\n",
            "Training Set:\n",
            "  Top-1 Accuracy: 57.46%\n",
            "  Top-5 Accuracy: 82.19%\n",
            "\n",
            "Validation Set:\n",
            "  Top-1 Accuracy: 57.04%\n",
            "  Top-5 Accuracy: 81.81%\n",
            "\n",
            "\n",
            "3. GENERATION QUALITY\n",
            "----------------------------------------\n",
            "Entropy:             6.1122 bits\n",
            "Generation Perplexity: 69.1781\n",
            "Unique Graphemes:    165/454\n",
            "Diversity Score:     36.34%\n",
            "\n",
            "\n",
            "4. MODEL INFORMATION\n",
            "----------------------------------------\n",
            "Vocabulary Size:     454\n",
            "Embedding Dimension: 96\n",
            "Number of Layers:    4\n",
            "Number of Heads:     3\n",
            "Block Size:          256\n",
            "Dropout:             0.2\n",
            "Total Parameters:    0.56M\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "@torch.no_grad()\n",
        "def calculate_perplexity(split='val', num_batches=None):\n",
        "    \"\"\"\n",
        "    Calculate perplexity on a dataset split.\n",
        "    Perplexity = exp(average cross-entropy loss)\n",
        "    Lower perplexity means better model.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    if num_batches is None:\n",
        "        num_batches = eval_iters\n",
        "\n",
        "    total_loss = 0\n",
        "    total_tokens = 0\n",
        "\n",
        "    for _ in range(num_batches):\n",
        "        X, Y = get_batch(split)\n",
        "         # Pass X only so logits remain (B, T, C)\n",
        "        logits, _ = model(X)\n",
        "\n",
        "        # Compute cross-entropy manually\n",
        "        B, T, C = logits.shape\n",
        "        loss = F.cross_entropy(logits.reshape(B * T, C), Y.reshape(B * T))\n",
        "\n",
        "        # Accumulate weighted by token count\n",
        "        n_tokens = B * T\n",
        "        total_loss += loss.item() * n_tokens\n",
        "        total_tokens += n_tokens\n",
        "\n",
        "    avg_loss = total_loss / total_tokens\n",
        "    perplexity = math.exp(avg_loss)\n",
        "\n",
        "    return perplexity, avg_loss\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_accuracy(split='val', num_batches=100):\n",
        "    \"\"\"\n",
        "    Calculate top-1 and top-5 accuracy for next grapheme prediction.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    top1_correct = 0\n",
        "    top5_correct = 0\n",
        "    total_predictions = 0\n",
        "\n",
        "    for _ in range(num_batches):\n",
        "        X, Y = get_batch(split)\n",
        "        logits, _ = model(X)\n",
        "\n",
        "        # Get predictions\n",
        "        B, T, C = logits.shape\n",
        "        logits_flat = logits.view(B * T, C)\n",
        "        targets_flat = Y.view(B * T)\n",
        "\n",
        "        # Top-1 accuracy\n",
        "        top1_preds = logits_flat.argmax(dim=-1)\n",
        "        top1_correct += (top1_preds == targets_flat).sum().item()\n",
        "\n",
        "        # Top-5 accuracy\n",
        "        top5_preds = logits_flat.topk(5, dim=-1).indices\n",
        "        top5_correct += sum(\n",
        "            targets_flat[i] in top5_preds[i]\n",
        "            for i in range(len(targets_flat))\n",
        "        )\n",
        "\n",
        "        total_predictions += B * T\n",
        "\n",
        "    top1_acc = top1_correct / total_predictions\n",
        "    top5_acc = top5_correct / total_predictions\n",
        "\n",
        "    return top1_acc, top5_acc\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def calculate_entropy(num_samples=10, max_length=200):\n",
        "    \"\"\"\n",
        "    Calculate the entropy of generated text.\n",
        "    Higher entropy means more diverse/random output.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_graphemes = []\n",
        "\n",
        "    for _ in range(num_samples):\n",
        "        context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "        generated = model.generate(context, max_new_tokens=max_length)\n",
        "        graphemes = [itog[idx] for idx in generated[0].tolist()]\n",
        "        all_graphemes.extend(graphemes)\n",
        "\n",
        "    # Calculate grapheme frequencies\n",
        "    grapheme_counts = Counter(all_graphemes)\n",
        "    total = len(all_graphemes)\n",
        "\n",
        "    # Calculate entropy: H = -sum(p * log(p))\n",
        "    entropy = 0\n",
        "    for count in grapheme_counts.values():\n",
        "        p = count / total\n",
        "        entropy -= p * math.log2(p)\n",
        "\n",
        "    # Calculate perplexity of generated text\n",
        "    gen_perplexity = 2 ** entropy\n",
        "\n",
        "    # Unique graphemes used\n",
        "    unique_used = len(grapheme_counts)\n",
        "    diversity = unique_used / vocab_size\n",
        "\n",
        "    return entropy, gen_perplexity, unique_used, diversity\n",
        "\n",
        "\n",
        "def evaluate_model_comprehensive():\n",
        "    \"\"\"\n",
        "    Comprehensive model evaluation with multiple metrics.\n",
        "    \"\"\"\n",
        "    print(\"=\" * 80)\n",
        "    print(\"COMPREHENSIVE MODEL EVALUATION\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # 1. Loss and Perplexity\n",
        "    print(\"\\n1. LOSS AND PERPLEXITY\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    train_ppl, train_loss = calculate_perplexity('train', num_batches=200)\n",
        "    val_ppl, val_loss = calculate_perplexity('val', num_batches=200)\n",
        "\n",
        "    print(f\"Training Set:\")\n",
        "    print(f\"  Loss:       {train_loss:.4f}\")\n",
        "    print(f\"  Perplexity: {train_ppl:.4f}\")\n",
        "    print(f\"\\nValidation Set:\")\n",
        "    print(f\"  Loss:       {val_loss:.4f}\")\n",
        "    print(f\"  Perplexity: {val_ppl:.4f}\")\n",
        "\n",
        "    # 2. Accuracy Metrics\n",
        "    print(\"\\n\\n2. PREDICTION ACCURACY\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    train_top1, train_top5 = calculate_accuracy('train', num_batches=100)\n",
        "    val_top1, val_top5 = calculate_accuracy('val', num_batches=100)\n",
        "\n",
        "    print(f\"Training Set:\")\n",
        "    print(f\"  Top-1 Accuracy: {train_top1*100:.2f}%\")\n",
        "    print(f\"  Top-5 Accuracy: {train_top5*100:.2f}%\")\n",
        "    print(f\"\\nValidation Set:\")\n",
        "    print(f\"  Top-1 Accuracy: {val_top1*100:.2f}%\")\n",
        "    print(f\"  Top-5 Accuracy: {val_top5*100:.2f}%\")\n",
        "\n",
        "    # 3. Generation Quality Metrics\n",
        "    print(\"\\n\\n3. GENERATION QUALITY\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    entropy, gen_ppl, unique_used, diversity = calculate_entropy(\n",
        "        num_samples=10, max_length=200\n",
        "    )\n",
        "\n",
        "    print(f\"Entropy:             {entropy:.4f} bits\")\n",
        "    print(f\"Generation Perplexity: {gen_ppl:.4f}\")\n",
        "    print(f\"Unique Graphemes:    {unique_used}/{vocab_size}\")\n",
        "    print(f\"Diversity Score:     {diversity*100:.2f}%\")\n",
        "\n",
        "    # 4. Model Information\n",
        "    print(\"\\n\\n4. MODEL INFORMATION\")\n",
        "    print(\"-\" * 40)\n",
        "    print(f\"Vocabulary Size:     {vocab_size}\")\n",
        "    print(f\"Embedding Dimension: {n_embd}\")\n",
        "    print(f\"Number of Layers:    {n_layer}\")\n",
        "    print(f\"Number of Heads:     {n_head}\")\n",
        "    print(f\"Block Size:          {block_size}\")\n",
        "    print(f\"Dropout:             {dropout}\")\n",
        "    print(f\"Total Parameters:    {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "\n",
        "    # Return metrics as dictionary\n",
        "    return {\n",
        "        'train_loss': train_loss,\n",
        "        'train_perplexity': train_ppl,\n",
        "        'val_loss': val_loss,\n",
        "        'val_perplexity': val_ppl,\n",
        "        'train_top1_accuracy': train_top1,\n",
        "        'train_top5_accuracy': train_top5,\n",
        "        'val_top1_accuracy': val_top1,\n",
        "        'val_top5_accuracy': val_top5,\n",
        "        'generation_entropy': entropy,\n",
        "        'generation_perplexity': gen_ppl,\n",
        "        'unique_graphemes_used': unique_used,\n",
        "        'diversity_score': diversity,\n",
        "    }\n",
        "\n",
        "# Run comprehensive evaluation\n",
        "metrics = evaluate_model_comprehensive()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "HB3gtfc0gn1A",
        "outputId": "2a84ec96-58bd-43f3-9938-9895fc574446"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1400x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training curves saved to 'training_curves.png'\n"
          ]
        }
      ],
      "source": [
        "# Plot training curves if we saved them\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "    if len(train_losses) > 0 and len(val_losses) > 0:\n",
        "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "        # Loss curves\n",
        "        steps = [i * eval_interval for i in range(len(train_losses))]\n",
        "        ax1.plot(steps, train_losses, label='Train Loss', marker='o')\n",
        "        ax1.plot(steps, val_losses, label='Val Loss', marker='s')\n",
        "        ax1.set_xlabel('Training Steps')\n",
        "        ax1.set_ylabel('Loss')\n",
        "        ax1.set_title('Training and Validation Loss')\n",
        "        ax1.legend()\n",
        "        ax1.grid(True, alpha=0.3)\n",
        "\n",
        "        # Perplexity curves\n",
        "        train_ppls = [math.exp(loss) for loss in train_losses]\n",
        "        val_ppls = [math.exp(loss) for loss in val_losses]\n",
        "        ax2.plot(steps, train_ppls, label='Train Perplexity', marker='o')\n",
        "        ax2.plot(steps, val_ppls, label='Val Perplexity', marker='s')\n",
        "        ax2.set_xlabel('Training Steps')\n",
        "        ax2.set_ylabel('Perplexity')\n",
        "        ax2.set_title('Training and Validation Perplexity')\n",
        "        ax2.legend()\n",
        "        ax2.grid(True, alpha=0.3)\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('training_curves.png', dpi=150, bbox_inches='tight')\n",
        "        plt.show()\n",
        "        print(\"Training curves saved to 'training_curves.png'\")\n",
        "except ImportError:\n",
        "    print(\"Matplotlib not available. Install it to visualize training curves.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not plot training curves: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bguF-1EVgn1A",
        "outputId": "cb9931bc-b873-442b-88b3-2e52012173f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "GRAPHEME DISTRIBUTION ANALYSIS\n",
            "================================================================================\n",
            "\n",
            "Top 20 Most Common Graphemes:\n",
            "--------------------------------------------------------------------------------\n",
            "Rank   Grapheme     Real %       Generated %  Difference  \n",
            "--------------------------------------------------------------------------------\n",
            "1                        15.07%      15.02%      -0.05%\n",
            "2      க                  3.57%       3.73%      +0.16%\n",
            "3      தி                 2.62%       2.02%      -0.60%\n",
            "4      ர்                 2.37%       2.13%      -0.24%\n",
            "5      த்                 2.18%       1.99%      -0.19%\n",
            "6      க்                 2.13%       1.97%      -0.16%\n",
            "7      ம்                 2.11%       2.07%      -0.04%\n",
            "8      த                  2.02%       2.09%      +0.07%\n",
            "9      ப                  1.96%       2.04%      +0.08%\n",
            "10     ல்                 1.93%       2.11%      +0.18%\n",
            "11     து                 1.90%       2.02%      +0.12%\n",
            "12     வ                  1.75%       1.74%      -0.01%\n",
            "13     ன்                 1.66%       1.94%      +0.28%\n",
            "14     ப்                 1.62%       1.59%      -0.03%\n",
            "15     ட                  1.61%       1.68%      +0.07%\n",
            "16     ய                  1.47%       1.27%      -0.20%\n",
            "17     ட்                 1.47%       1.62%      +0.15%\n",
            "18     ள்                 1.40%       1.57%      +0.17%\n",
            "19     கு                 1.38%       1.35%      -0.03%\n",
            "20     அ                  1.36%       1.39%      +0.03%\n",
            "\n",
            "KL Divergence (Real || Generated): 0.0465\n",
            "(Lower is better - 0 means identical distributions)\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "# Analyze grapheme distribution in generated vs. real text\n",
        "def analyze_grapheme_distribution():\n",
        "    \"\"\"\n",
        "    Compare grapheme frequency distribution between generated and real text.\n",
        "    \"\"\"\n",
        "    print(\"\\nGRAPHEME DISTRIBUTION ANALYSIS\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "    # Get real text graphemes (sample)\n",
        "    real_sample = all_graphemes[:10000]  # First 10k graphemes\n",
        "    real_counts = Counter(real_sample)\n",
        "\n",
        "    # Generate text\n",
        "    model.eval()\n",
        "    generated_graphemes = []\n",
        "    for _ in range(5):\n",
        "        context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "        generated = model.generate(context, max_new_tokens=2000)\n",
        "        graphemes = [itog[idx] for idx in generated[0].tolist()]\n",
        "        generated_graphemes.extend(graphemes)\n",
        "\n",
        "    gen_counts = Counter(generated_graphemes)\n",
        "\n",
        "    # Compare top-20 most common graphemes\n",
        "    print(\"\\nTop 20 Most Common Graphemes:\")\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"{'Rank':<6} {'Grapheme':<12} {'Real %':<12} {'Generated %':<12} {'Difference':<12}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    real_total = sum(real_counts.values())\n",
        "    gen_total = sum(gen_counts.values())\n",
        "\n",
        "    for rank, (grapheme, real_count) in enumerate(real_counts.most_common(20), 1):\n",
        "        real_pct = (real_count / real_total) * 100\n",
        "        gen_count = gen_counts.get(grapheme, 0)\n",
        "        gen_pct = (gen_count / gen_total) * 100\n",
        "        diff = gen_pct - real_pct\n",
        "\n",
        "        print(f\"{rank:<6} {grapheme:<12} {real_pct:>10.2f}% {gen_pct:>10.2f}% {diff:>+10.2f}%\")\n",
        "\n",
        "    # Calculate KL divergence (simplified)\n",
        "    all_graphemes_set = set(real_counts.keys()) | set(gen_counts.keys())\n",
        "    kl_div = 0\n",
        "    for g in all_graphemes_set:\n",
        "        p = (real_counts.get(g, 0) + 1) / (real_total + len(all_graphemes_set))  # Laplace smoothing\n",
        "        q = (gen_counts.get(g, 0) + 1) / (gen_total + len(all_graphemes_set))\n",
        "        kl_div += p * math.log(p / q)\n",
        "\n",
        "    print(f\"\\nKL Divergence (Real || Generated): {kl_div:.4f}\")\n",
        "    print(\"(Lower is better - 0 means identical distributions)\")\n",
        "    print(\"=\" * 80)\n",
        "\n",
        "analyze_grapheme_distribution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Saf9B5xRgn1B",
        "outputId": "1e0e6985-b76c-44bd-a117-808c9728664b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Vocabulary Statistics:\n",
            "Total unique graphemes: 454\n",
            "Sample graphemes (first 30): ['\\n', ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '=']\n",
            "Sample graphemes (last 30): ['ஸா', 'ஸி', 'ஸீ', 'ஸு', 'ஸூ', 'ஸெ', 'ஸொ', 'ஸே', 'ஸை', 'ஸொ', 'ஸோ', 'ஸ்', 'ஹ', 'ஹா', 'ஹி', 'ஹீ', 'ஹு', 'ஹூ', 'ஹெ', 'ஹே', 'ஹோ', 'ஹை', 'ஹொ', 'ஹோ', 'ஹ்', '‐', '–', '…', '\\u2028', '\\ue38d']\n"
          ]
        }
      ],
      "source": [
        "# Check vocabulary statistics\n",
        "print(f\"\\nVocabulary Statistics:\")\n",
        "print(f\"Total unique graphemes: {vocab_size}\")\n",
        "print(f\"Sample graphemes (first 30): {unique_graphemes[:30]}\")\n",
        "print(f\"Sample graphemes (last 30): {unique_graphemes[-30:]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "roomn5GRgn1B",
        "outputId": "397888f2-4393-41ee-c4cb-c5918517c47c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model info saved to grapheme_model_info.json\n",
            "\n",
            "Model Summary:\n",
            "{\n",
            "  \"vocab_size\": 454,\n",
            "  \"n_embd\": 96,\n",
            "  \"n_head\": 3,\n",
            "  \"n_layer\": 4,\n",
            "  \"block_size\": 256,\n",
            "  \"dropout\": 0.2,\n",
            "  \"total_params\": 558598,\n",
            "  \"batch_size\": 64,\n",
            "  \"learning_rate\": 0.0002,\n",
            "  \"max_iters\": 30000,\n",
            "  \"metrics\": {\n",
            "    \"train_loss\": 1.6119494611024856,\n",
            "    \"train_perplexity\": 5.01257352624412,\n",
            "    \"val_loss\": 1.6399694728851317,\n",
            "    \"val_perplexity\": 5.155012142184854,\n",
            "    \"train_top1_accuracy\": 0.5745782470703125,\n",
            "    \"train_top5_accuracy\": 0.8218817138671874,\n",
            "    \"val_top1_accuracy\": 0.570361328125,\n",
            "    \"val_top5_accuracy\": 0.8181488037109375,\n",
            "    \"generation_entropy\": 6.112243169905192,\n",
            "    \"generation_perplexity\": 69.17808488941837,\n",
            "    \"unique_graphemes_used\": 165,\n",
            "    \"diversity_score\": 0.3634361233480176\n",
            "  }\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "# Save comprehensive model info and metrics\n",
        "model_info = {\n",
        "    # Model architecture\n",
        "    'vocab_size': vocab_size,\n",
        "    'n_embd': n_embd,\n",
        "    'n_head': n_head,\n",
        "    'n_layer': n_layer,\n",
        "    'block_size': block_size,\n",
        "    'dropout': dropout,\n",
        "    'total_params': sum(p.numel() for p in model.parameters()),\n",
        "\n",
        "    # Training info\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': learning_rate,\n",
        "    'max_iters': max_iters,\n",
        "\n",
        "    # Performance metrics\n",
        "    'metrics': metrics,\n",
        "}\n",
        "\n",
        "import json\n",
        "with open('grapheme_model_info.json', 'w', encoding='utf-8') as f:\n",
        "    json.dump(model_info, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\nModel info saved to grapheme_model_info.json\")\n",
        "print(\"\\nModel Summary:\")\n",
        "print(json.dumps(model_info, indent=2, ensure_ascii=False))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}